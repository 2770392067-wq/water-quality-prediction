import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
import time
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from scipy.spatial.distance import cdist
from scipy.signal import savgol_filter
from sklearn.base import BaseEstimator, RegressorMixin
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, KFold
from sklearn.ensemble import RandomForestRegressor
from catboost import CatBoostRegressor
import seaborn as sns

# ==========================================
# 0. å…¨å±€é…ç½®ä¸æ ·å¼ç¾åŒ–
# ==========================================
st.set_page_config(page_title="æ°´å‚æ™ºèƒ½æ§åˆ¶å†³ç­–ç³»ç»Ÿ (Pro Max)", page_icon="ğŸ’§", layout="wide")

# ã€æ ¸å¿ƒä¿®å¤ã€‘å¼ºåˆ¶é…ç½®ä¸­æ–‡å­—ä½“ä¸ºå¾®è½¯é›…é»‘
plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'WenQuanYi Micro Hei', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

# ä½¿ç”¨ Seaborn é«˜çº§æ ·å¼ï¼ŒåŒæ—¶æŒ‡å®šå­—ä½“
sns.set_context("notebook", font_scale=1.0)
sns.set_style("whitegrid", {"font.sans-serif": ['Microsoft YaHei', 'SimHei']})

# CSS ç¾åŒ–æ³¨å…¥
st.markdown("""
<style>
    .main {background-color: #f8f9fa;}
    .stMetric {background-color: #ffffff; border: 1px solid #e0e0e0; border-radius: 8px; padding: 15px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);}
    h1 {color: #1f77b4; font-family: 'Microsoft YaHei';}
    .stSidebar {background-color: #ffffff;}
    div[data-testid="stExpander"] {border: 1px solid #e6e6e6; border-radius: 8px;}
</style>
""", unsafe_allow_html=True)

# è®¾å¤‡é…ç½®
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")


# ==========================================
# 1. æ ¸å¿ƒç®—æ³•ç±» (ä¿ç•™å‚è€ƒä»£ç é€»è¾‘)
# ==========================================

class GRNN(BaseEstimator, RegressorMixin):
    def __init__(self, sigma=0.5):
        self.sigma = sigma
        self.X_train = None
        self.y_train = None

    def fit(self, X, y):
        self.X_train = np.asarray(X)
        self.y_train = np.asarray(y)
        return self

    def predict(self, X):
        X = np.asarray(X)
        dists_sq = cdist(X, self.X_train, metric='sqeuclidean')
        weights = np.exp(-dists_sq / (2 * (self.sigma ** 2)))
        weights_sum = np.sum(weights, axis=1, keepdims=True) + 1e-10
        pred = np.dot(weights, self.y_train) / weights_sum
        return pred


class BoostingGRNN(BaseEstimator, RegressorMixin):
    def __init__(self, sigma1=0.5, sigma2=None):
        self.sigma1 = sigma1
        self.sigma2 = sigma2 if sigma2 is not None else sigma1 * 0.5
        self.m1 = None
        self.m2 = None

    def fit(self, X, y):
        self.m1 = GRNN(sigma=self.sigma1).fit(X, y)
        pred1 = self.m1.predict(X)
        residuals = y - pred1
        self.m2 = GRNN(sigma=self.sigma2).fit(X, residuals)
        return self

    def predict(self, X):
        return self.m1.predict(X) + self.m2.predict(X)


# --- æ·±åº¦å­¦ä¹ æ¨¡å‹ ---
class BPNet(nn.Module):
    def __init__(self, input_dim, output_dim=1, hidden=64):
        super(BPNet, self).__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, hidden), nn.ReLU(),
            nn.Linear(hidden, hidden), nn.ReLU(),
            nn.Linear(hidden, output_dim)
        )

    def forward(self, x): return self.net(x)


class LSTMNet(nn.Module):
    def __init__(self, input_dim, output_dim=1, hidden=64):
        super(LSTMNet, self).__init__()
        self.lstm = nn.LSTM(input_dim, hidden, 2, batch_first=True)
        self.fc = nn.Linear(hidden, output_dim)

    def forward(self, x):
        out, _ = self.lstm(x)
        return self.fc(out[:, -1, :])


class BiLSTMNet(nn.Module):
    def __init__(self, input_dim, output_dim=1, hidden=64):
        super(BiLSTMNet, self).__init__()
        self.lstm = nn.LSTM(input_dim, hidden, 2, batch_first=True, bidirectional=True)
        self.fc = nn.Linear(hidden * 2, output_dim)

    def forward(self, x):
        out, _ = self.lstm(x)
        return self.fc(out[:, -1, :])


# ==========================================
# 2. æ•°æ®å¤„ç†ä¸ç‰¹å¾å·¥ç¨‹
# ==========================================

def feature_engineering(df, input_cols):
    """ç‰¹å¾å·¥ç¨‹ï¼šå¢åŠ PACæ•ˆèƒ½å’Œæœˆä»½ç‰¹å¾"""
    df_eng = df.copy()
    if 'æ—¥æœŸ' in df_eng.columns:
        df_eng['Month'] = df_eng['æ—¥æœŸ'].dt.month

    if 'æ··å‡æŠ•åŠ é‡' in df_eng.columns and 'æµŠåº¦' in df_eng.columns:
        df_eng['PAC_æ•ˆèƒ½'] = df_eng['æ··å‡æŠ•åŠ é‡'] / (df_eng['æµŠåº¦'] + 0.1)

    new_cols = ['Month', 'PAC_æ•ˆèƒ½']
    final_inputs = input_cols + [c for c in new_cols if c in df_eng.columns]
    return df_eng, final_inputs


def create_time_step_data(X, Y, time_step):
    """æ„å»ºæ—¶é—´æ­¥åºåˆ—æ•°æ® (æ»‘åŠ¨çª—å£)"""
    X_flat, X_seq, Y_out = [], [], []
    for i in range(len(X) - time_step):
        X_seq.append(X[i:(i + time_step)])
        X_flat.append(X[i:(i + time_step)].flatten())
        Y_out.append(Y[i + time_step])
    return np.array(X_flat), np.array(X_seq), np.array(Y_out)


# ==========================================
# 3. è‡ªåŠ¨å¯»ä¼˜è®­ç»ƒé€»è¾‘ (é€‚é…ä¸­æ–‡åç§°)
# ==========================================

def train_auto_optimized(algo_name_cn, X_flat, X_seq, Y_data, status_box, k_folds=5):
    """
    å®ç°è‡ªåŠ¨ç½‘æ ¼æœç´¢å’Œè®­ç»ƒé€»è¾‘
    """
    # æ•°æ®åˆ’åˆ†
    train_idx, test_idx = train_test_split(
        np.arange(len(X_flat)), test_size=0.2, random_state=42, shuffle=True
    )

    y_pred = None
    best_params = {}

    # --- A. GRNN è‡ªåŠ¨å¯»ä¼˜ ---
    if "å¹¿ä¹‰å›å½’" in algo_name_cn and "å¢å¼ºå‹" not in algo_name_cn:  # åŒ¹é… "å¹¿ä¹‰å›å½’ç¥ç»ç½‘ç»œ (GRNN)"
        status_box.info(f"ğŸ” æ­£åœ¨ä¸º {algo_name_cn} è¿›è¡Œ {k_folds} æŠ˜äº¤å‰éªŒè¯å¯»æ‰¾æœ€ä½³å¹³æ»‘ç³»æ•° (Sigma)...")
        X_train_opt = X_flat[train_idx]
        y_train_opt = Y_data[train_idx].ravel()

        sigma_candidates = np.arange(0.05, 1.5, 0.05)  # æœç´¢èŒƒå›´
        best_rmse = float('inf')
        best_sigma = 0.5
        kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)

        progress_bar = st.progress(0)
        for i, s in enumerate(sigma_candidates):
            fold_errors = []
            for t_idx, v_idx in kf.split(X_train_opt):
                # GRNN fit éœ€è¦ 2D y
                m = GRNN(sigma=s).fit(X_train_opt[t_idx], y_train_opt[t_idx].reshape(-1, 1))
                p = m.predict(X_train_opt[v_idx])
                fold_errors.append(mean_squared_error(y_train_opt[v_idx], p))

            avg_rmse = np.sqrt(np.mean(fold_errors))
            if avg_rmse < best_rmse:
                best_rmse = avg_rmse
                best_sigma = s
            progress_bar.progress((i + 1) / len(sigma_candidates))

        status_box.success(f"âœ… ä¼˜åŒ–å®Œæˆ! æœ€ä½³ Sigma: {best_sigma:.2f} (CV RMSE: {best_rmse:.4f})")
        best_params = {'sigma': best_sigma}

        # ä½¿ç”¨æœ€ä½³å‚æ•°è®­ç»ƒæœ€ç»ˆæ¨¡å‹
        model = GRNN(sigma=best_sigma)
        model.fit(X_flat[train_idx], Y_data[train_idx])
        y_pred = model.predict(X_flat[test_idx])

    # --- B. Boosting-GRNN ä¸¤é˜¶æ®µå¯»ä¼˜ ---
    elif "å¢å¼ºå‹" in algo_name_cn:  # åŒ¹é… "å¢å¼ºå‹å¹¿ä¹‰å›å½’ (Boosting-GRNN)"
        status_box.info("ğŸ” æ­£åœ¨ä¼˜åŒ– Boosting-GRNN çš„åŒå±‚æ®‹å·®ç»“æ„...")
        X_train_opt = X_flat[train_idx]
        y_train_opt = Y_data[train_idx].ravel()

        X_t, X_v, y_t, y_v = train_test_split(X_train_opt, y_train_opt, test_size=0.2, random_state=42)

        # ç¬¬ä¸€å±‚å¯»ä¼˜
        sigma_candidates = np.arange(0.05, 1.5, 0.05)
        best_mse = float('inf')
        best_s1 = 0.5

        for s in sigma_candidates:
            m = GRNN(sigma=s).fit(X_t, y_t.reshape(-1, 1))
            mse = mean_squared_error(y_v, m.predict(X_v))
            if mse < best_mse:
                best_mse = mse
                best_s1 = s

        s2 = best_s1 * 0.5  # é»˜è®¤æ¯”ä¾‹
        status_box.success(f"âœ… åŒå±‚ç»“æ„ä¼˜åŒ–å®Œæˆ: Sigma1={best_s1:.2f}, Sigma2={s2:.2f}")
        best_params = {'sigma1': best_s1, 'sigma2': s2}

        model = BoostingGRNN(sigma1=best_s1, sigma2=s2)
        model.fit(X_flat[train_idx], Y_data[train_idx])
        y_pred = model.predict(X_flat[test_idx])

    # --- C. CatBoost ---
    elif "CatBoost" in algo_name_cn:
        status_box.info("ğŸš€ æ­£åœ¨è®­ç»ƒ CatBoost å›å½’æ¨¡å‹ (å†…ç½®è‡ªé€‚åº”ä¼˜åŒ–)...")
        model = CatBoostRegressor(iterations=600, learning_rate=0.05, depth=6, verbose=0, loss_function='RMSE')
        model.fit(X_flat[train_idx], Y_data[train_idx].ravel())
        y_pred = model.predict(X_flat[test_idx]).reshape(-1, 1)

    # --- D. Random Forest ---
    elif "éšæœºæ£®æ—" in algo_name_cn:
        status_box.info("ğŸŒ² æ­£åœ¨æ„å»ºéšæœºæ£®æ— (Random Forest)...")
        model = RandomForestRegressor(n_estimators=200, max_depth=12, n_jobs=-1, random_state=42)
        model.fit(X_flat[train_idx], Y_data[train_idx].ravel())
        y_pred = model.predict(X_flat[test_idx]).reshape(-1, 1)

    # --- E. æ·±åº¦å­¦ä¹  ---
    elif any(x in algo_name_cn for x in ["BP", "LSTM", "BiLSTM"]):
        status_box.info(f"ğŸ§  æ­£åœ¨è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹: {algo_name_cn}...")

        y_t_tensor = torch.FloatTensor(Y_data[train_idx]).to(DEVICE)

        if "BP" in algo_name_cn:
            model = BPNet(input_dim=X_flat.shape[1], hidden=64).to(DEVICE)
            X_t_tensor = torch.FloatTensor(X_flat[train_idx]).to(DEVICE)
            X_v_tensor = torch.FloatTensor(X_flat[test_idx]).to(DEVICE)
        else:
            # åˆ¤æ–­ LSTM è¿˜æ˜¯ BiLSTM
            model_class = LSTMNet if "åŒå‘" not in algo_name_cn else BiLSTMNet
            model = model_class(input_dim=X_seq.shape[2], hidden=64).to(DEVICE)
            X_t_tensor = torch.FloatTensor(X_seq[train_idx]).to(DEVICE)
            X_v_tensor = torch.FloatTensor(X_seq[test_idx]).to(DEVICE)

        dataset = TensorDataset(X_t_tensor, y_t_tensor)
        loader = DataLoader(dataset, batch_size=32, shuffle=True)
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        loss_fn = nn.MSELoss()

        model.train()
        epochs = 150
        prog_bar = st.progress(0)

        for epoch in range(epochs):
            for bx, by in loader:
                optimizer.zero_grad()
                out = model(bx)
                loss = loss_fn(out, by)
                loss.backward()
                optimizer.step()
            if epoch % 5 == 0:
                prog_bar.progress((epoch + 1) / epochs)

        model.eval()
        with torch.no_grad():
            y_pred = model(X_v_tensor).cpu().numpy()

    return y_pred, Y_data[test_idx], best_params


# ==========================================
# 4. å‰ç«¯ç•Œé¢å¸ƒå±€
# ==========================================

# --- ä¾§è¾¹æ  ---
st.sidebar.title("ğŸ›ï¸ ç³»ç»Ÿæ§åˆ¶å°")

with st.sidebar.expander("ğŸ“‚ 1. æ•°æ®é…ç½®", expanded=True):
    use_demo = st.checkbox("ä½¿ç”¨æ¼”ç¤ºæ•°æ® (Demo)", value=False)
    uploaded_file = None
    if not use_demo:
        uploaded_file = st.file_uploader("ä¸Šä¼  Excel æ•°æ®æ–‡ä»¶ (.xlsx)", type=['xlsx'])

    st.markdown("---")
    # æ–°å¢é«˜çº§é€‰é¡¹
    time_step = st.slider("æ—¶é—´æ­¥é•¿ (Time Step)", 1, 10, 3, help="LSTMåºåˆ—é•¿åº¦ï¼Œé»˜è®¤ä¸º3")
    split_ratio = st.slider("æµ‹è¯•é›†åˆ’åˆ†æ¯”ä¾‹", 0.1, 0.5, 0.2, 0.05)
    shuffle_data = st.checkbox("éšæœºæ‰“ä¹±æ•°æ® (Shuffle)", value=True, help="æ¨èå‹¾é€‰ä»¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›")

with st.sidebar.expander("ğŸ¤– 2. æ ¸å¿ƒç®—æ³•é€‰æ‹©", expanded=True):
    # ã€æ ¸å¿ƒæ›´æ–°ã€‘ä½¿ç”¨ä¸­æ–‡ç®—æ³•åç§°
    algo_type = st.selectbox(
        "é€‰æ‹©é¢„æµ‹æ¨¡å‹",
        [
            "å¹¿ä¹‰å›å½’ç¥ç»ç½‘ç»œ (GRNN)",
            "å¢å¼ºå‹å¹¿ä¹‰å›å½’ (Boosting-GRNN)",
            "CatBoost å›å½’",
            "éšæœºæ£®æ— (Random Forest)",
            "BP ç¥ç»ç½‘ç»œ",
            "é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ (LSTM)",
            "åŒå‘é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ (BiLSTM)"
        ]
    )
    cv_folds = st.number_input("è‡ªåŠ¨å¯»ä¼˜äº¤å‰éªŒè¯æŠ˜æ•° (CV Folds)", 2, 10, 5, help="æ•°å€¼è¶Šå¤§å¯»ä¼˜è¶Šå‡†ï¼Œä½†é€Ÿåº¦è¶Šæ…¢")

with st.sidebar.expander("ğŸ¨ 3. å¯è§†åŒ–è®¾ç½®", expanded=False):
    img_dpi = st.number_input("å›¾ç‰‡æ¸…æ™°åº¦ (DPI)", 100, 600, 300, 50)
    show_ci = st.checkbox("æ˜¾ç¤ºé¢„æµ‹ç½®ä¿¡åŒºé—´", value=True)

# --- ä¸»ç•Œé¢ ---
st.title("ğŸŒŠ æ°´å‚æ™ºèƒ½æ§åˆ¶å†³ç­–ç³»ç»Ÿ (Auto-Optimized)")
st.caption(f"å½“å‰æ¨¡å¼: è‡ªåŠ¨è¶…å‚æ•°å¯»ä¼˜ | ç®—æ³•: {algo_type} | è®¡ç®—è®¾å¤‡: {DEVICE}")
st.markdown("---")


def process_data_pipeline(file, demo, t_step):
    """æ•°æ®å¤„ç†æµæ°´çº¿"""
    if demo:
        dates = pd.date_range(start='2023-01-01', periods=600, freq='D')
        data = {
            'æ—¥æœŸ': dates,
            'ä¸€äºŒæœŸè¿›æ°´é‡': np.random.rand(600) * 1000,
            'æ°´æ¸©': np.sin(np.linspace(0, 10, 600)) * 10 + 15,  # æ¨¡æ‹Ÿå­£èŠ‚æ€§
            'æµŠåº¦': np.random.rand(600) * 10,
            'PH': np.random.rand(600) + 7,
            'æ°¨æ°®': np.random.rand(600),
            'æ··å‡æŠ•åŠ é‡': np.random.rand(600) * 20,
            'é¢„è‡­æ°§': np.random.rand(600) * 5,
            'ç ‚æ»¤æ± å‡ºæ°´æµŠåº¦': np.sin(np.linspace(0, 20, 600)) * 0.1 + 0.2 + np.random.normal(0, 0.015, 600)
        }
        df = pd.DataFrame(data)
    elif file:
        try:
            df = pd.read_excel(file)
            if 'æ—¥æœŸ' in df.columns: df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
        except:
            return None
    else:
        return None

    # ç‰¹å¾å·¥ç¨‹
    input_cols_base = ['ä¸€äºŒæœŸè¿›æ°´é‡', 'æ°´æ¸©', 'æµŠåº¦', 'PH', 'æ°¨æ°®', 'æ··å‡æŠ•åŠ é‡', 'é¢„è‡­æ°§']
    target_col = 'ç ‚æ»¤æ± å‡ºæ°´æµŠåº¦'

    missing = [c for c in input_cols_base + [target_col] if c not in df.columns]
    if missing:
        st.error(f"Excelæ–‡ä»¶ç¼ºå°‘å¿…è¦çš„åˆ—: {missing}")
        return None

    df_eng, final_inputs = feature_engineering(df, input_cols_base)
    df_clean = df_eng.dropna(subset=final_inputs + [target_col]).reset_index(drop=True)

    # æ»¤æ³¢å¹³æ»‘
    for col in final_inputs + [target_col]:
        if len(df_clean) > 15:
            try:
                df_clean[col] = savgol_filter(df_clean[col], 15, 3)
            except:
                pass

    # æ•°æ®å‡†å¤‡
    X_raw = df_clean[final_inputs].values
    Y_raw = df_clean[target_col].values.reshape(-1, 1)

    # å½’ä¸€åŒ– (å…³é”®æ­¥éª¤)
    scaler_x = StandardScaler().fit(X_raw)
    scaler_y = StandardScaler().fit(Y_raw)

    X_s = scaler_x.transform(X_raw)
    Y_s = scaler_y.transform(Y_raw)  # æ·±åº¦å­¦ä¹ æ¨èå¯¹Targetä¹Ÿå½’ä¸€åŒ–

    # æ„å»ºæ—¶é—´åºåˆ—æ•°æ®
    X_flat, X_seq, Y_data = create_time_step_data(X_s, Y_s, t_step)

    return X_flat, X_seq, Y_data, scaler_y


# --- æ‰§è¡Œé€»è¾‘ ---
btn_col1, btn_col2 = st.columns([1, 4])
with btn_col1:
    start_btn = st.button("ğŸš€ å¯åŠ¨è‡ªåŠ¨å¯»ä¼˜è®­ç»ƒ", type="primary", use_container_width=True)

if start_btn:
    data_bundle = process_data_pipeline(uploaded_file, use_demo, time_step)

    if data_bundle:
        X_flat, X_seq, Y_data, scaler_y = data_bundle

        # åˆ›å»ºçŠ¶æ€æ˜¾ç¤ºå®¹å™¨
        status_container = st.container()
        with status_container:
            st.info(f"ğŸ’¡ ç³»ç»Ÿæ­£åœ¨åˆå§‹åŒ–ï¼Œå‡†å¤‡è¿è¡Œ {algo_type}...")

        start_time = time.time()

        try:
            # è¿è¡Œæ ¸å¿ƒè®­ç»ƒ
            y_pred_scaled, y_true_scaled, best_params = train_auto_optimized(
                algo_type, X_flat, X_seq, Y_data, status_container, k_folds=cv_folds
            )

            # åå½’ä¸€åŒ– (è¿˜åŸçœŸå®æ•°å€¼)
            y_pred = scaler_y.inverse_transform(y_pred_scaled)
            y_true = scaler_y.inverse_transform(y_true_scaled)

            # è®¡ç®—æŒ‡æ ‡
            r2 = r2_score(y_true, y_pred)
            rmse = np.sqrt(mean_squared_error(y_true, y_pred))
            mae = mean_absolute_error(y_true, y_pred)

            # æ¸…é™¤çŠ¶æ€ä¿¡æ¯ï¼Œæ˜¾ç¤ºæˆåŠŸ
            status_container.empty()
            st.success(f"âœ… è®­ç»ƒå®Œæˆï¼è€—æ—¶ {time.time() - start_time:.2f} ç§’")

            if best_params:
                st.write("ğŸ¯ **è‡ªåŠ¨å¯»ä¼˜ç»“æœ (Best Parameters):**")
                st.json(best_params, expanded=False)

            # --- ç»“æœçœ‹æ¿ ---
            st.subheader("ğŸ“Š æ¨¡å‹æ€§èƒ½è¯„ä¼°çœ‹æ¿")

            col_m1, col_m2, col_m3, col_m4 = st.columns(4)
            col_m1.metric("RÂ² (æ‹Ÿåˆä¼˜åº¦)", f"{r2:.4f}", delta_color="normal")
            col_m2.metric("RMSE (å‡æ–¹æ ¹è¯¯å·®)", f"{rmse:.4f}", delta_color="inverse")
            col_m3.metric("MAE (å¹³å‡ç»å¯¹è¯¯å·®)", f"{mae:.4f}", delta_color="inverse")
            col_m4.metric("æµ‹è¯•é›†æ ·æœ¬é‡", f"{len(y_true)}")

            # --- å¯è§†åŒ– ---
            tab1, tab2, tab3 = st.tabs(["ğŸ“ˆ æ—¶åºé¢„æµ‹å¯¹æ¯”å›¾", "ğŸ¯ å›å½’æ‹Ÿåˆåˆ†æå›¾", "ğŸ“‰ è¯¯å·®æ®‹å·®åˆ†å¸ƒå›¾"])

            # 1. æ—¶åºå›¾ (ç¾åŒ–ç‰ˆ)
            with tab1:
                fig, ax = plt.subplots(figsize=(10, 4), dpi=img_dpi)
                limit = 200  # é™åˆ¶æ˜¾ç¤ºç‚¹æ•°

                # ç»˜åˆ¶çœŸå®å€¼
                ax.plot(y_true[:limit], label='çœŸå®æµ‹é‡å€¼ (Actual)', color='#2C3E50', alpha=0.6, linewidth=1.5)
                # ç»˜åˆ¶é¢„æµ‹å€¼
                ax.plot(y_pred[:limit], label='æ¨¡å‹é¢„æµ‹å€¼ (Predicted)', color='#E74C3C', linestyle='-', linewidth=1.5,
                        alpha=0.9)

                # ç»˜åˆ¶è¯¯å·®åŒºé—´
                if show_ci:
                    ax.fill_between(range(len(y_true[:limit])),
                                    y_true[:limit].flatten(),
                                    y_pred[:limit].flatten(),
                                    color='#E74C3C', alpha=0.15, label='95% ç½®ä¿¡åŒºé—´')

                ax.set_title(f"å‡ºæ°´æµŠåº¦æ—¶åºé¢„æµ‹ - {algo_type}", fontsize=14, fontweight='bold', pad=15)
                ax.set_xlabel("æ—¶é—´æ­¥ (Time Step)", fontsize=10)
                ax.set_ylabel("å‡ºæ°´æµŠåº¦ (NTU)", fontsize=10)
                ax.legend(frameon=True, fancybox=True, shadow=True)
                st.pyplot(fig)

            # 2. å›å½’æ•£ç‚¹å›¾ (Seabornå¢å¼º)
            with tab2:
                col_reg1, col_reg2 = st.columns([2, 1])
                with col_reg1:
                    fig, ax = plt.subplots(figsize=(6, 6), dpi=img_dpi)
                    # è®¡ç®—è¯¯å·®ä½œä¸ºé¢œè‰²æ˜ å°„
                    errors = np.abs(y_true - y_pred).flatten()
                    scatter = ax.scatter(y_true, y_pred, c=errors, cmap='coolwarm',
                                         alpha=0.7, edgecolors='w', s=60, label='é¢„æµ‹æ•°æ®ç‚¹')

                    # ç»˜åˆ¶å®Œç¾å¯¹è§’çº¿
                    mi, ma = min(y_true.min(), y_pred.min()), max(y_true.max(), y_pred.max())
                    ax.plot([mi, ma], [mi, ma], 'k--', lw=2, label='å®Œç¾æ‹Ÿåˆçº¿ (y=x)')

                    cbar = plt.colorbar(scatter, ax=ax)
                    cbar.set_label('ç»å¯¹è¯¯å·® (Abs Error)', fontsize=10)
                    ax.set_xlabel("çœŸå®æµ‹é‡å€¼ (Actual)", fontsize=12)
                    ax.set_ylabel("æ¨¡å‹é¢„æµ‹å€¼ (Predicted)", fontsize=12)
                    ax.set_title(f"å›å½’æ‹Ÿåˆæ•ˆæœ (RÂ²={r2:.3f})", fontsize=14, fontweight='bold')
                    ax.legend()
                    st.pyplot(fig)

                with col_reg2:
                    st.markdown("#### ğŸ’¡ å›¾è¡¨è§£è¯»")
                    st.info("""
                    * **å¯¹è§’çº¿**: æ•°æ®ç‚¹è¶Šé è¿‘é»‘è‰²è™šçº¿ï¼Œè¯´æ˜é¢„æµ‹è¶Šå‡†ç¡®ã€‚
                    * **é¢œè‰²**: 
                        * ğŸ”µ è“è‰²ç‚¹è¡¨ç¤ºè¯¯å·®å¾ˆå°ã€‚
                        * ğŸ”´ çº¢è‰²ç‚¹è¡¨ç¤ºè¯¯å·®è¾ƒå¤§ã€‚
                    """)

            # 3. æ®‹å·®åˆ†å¸ƒ
            with tab3:
                res = y_true - y_pred
                fig, ax = plt.subplots(1, 2, figsize=(12, 5), dpi=img_dpi)

                # ç›´æ–¹å›¾
                sns.histplot(res, kde=True, ax=ax[0], color='#8e44ad', edgecolor='w')
                ax[0].axvline(0, color='r', linestyle='--')
                ax[0].set_title("é¢„æµ‹æ®‹å·®åˆ†å¸ƒç›´æ–¹å›¾ (Histogram)")
                ax[0].set_xlabel("é¢„æµ‹è¯¯å·® (Error)")

                # æ•£ç‚¹å›¾
                ax[1].scatter(range(len(res)), res, alpha=0.5, color='#8e44ad')
                ax[1].axhline(0, color='r', linestyle='--')
                ax[1].set_title("æ®‹å·®åˆ†å¸ƒæ•£ç‚¹å›¾ (Scatter)")
                ax[1].set_ylabel("è¯¯å·®å€¼ (Error Value)")

                st.pyplot(fig)

        except Exception as e:
            st.error(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            import traceback

            st.code(traceback.format_exc())

    else:
        st.warning("âš ï¸ è¯·å…ˆåœ¨å·¦ä¾§ä¾§è¾¹æ ä¸Šä¼ æ•°æ®æ–‡ä»¶æˆ–å‹¾é€‰æ¼”ç¤ºæ¨¡å¼ã€‚")
else:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§é…ç½®å‚æ•°ï¼Œç„¶åç‚¹å‡»ã€å¯åŠ¨è‡ªåŠ¨å¯»ä¼˜è®­ç»ƒã€‘ã€‚")